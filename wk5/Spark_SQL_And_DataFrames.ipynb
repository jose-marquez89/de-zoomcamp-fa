{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e22bda62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56538e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b36cf7",
   "metadata": {},
   "source": [
    "# First Look at Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "741fa55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/15 15:29:07 WARN Utils: Your hostname, jose-MacBookPro resolves to a loopback address: 127.0.1.1; using 192.168.1.224 instead (on interface wlp2s0)\n",
      "23/06/15 15:29:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/15 15:29:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"test\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf33df4b",
   "metadata": {},
   "source": [
    "### Using pandas to derive a schema quickly\n",
    "\n",
    "If you're dealing with a large csv, you may want to start with a chunk of it first in pandas.\n",
    "\n",
    "Here's a bash/linux terminal command to cut things down to size, the exclamation mark should be used if you want to use the command in the context of the jupyter notebook:\n",
    "\n",
    "```\n",
    "!head -n 1001 file_name.csv > just_head.csv\n",
    "```\n",
    "\n",
    "Create a pandas dataframe with the reduced dataset.\n",
    "\n",
    "After this, you can use the method below to create a spark dataframe from a pandas dataframe:\n",
    "\n",
    "```\n",
    "spark.createDataFrame(pandas_df)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade4caa2",
   "metadata": {},
   "source": [
    "### Defining a schema manually\n",
    "```python\n",
    "from pyspark.sql import types\n",
    "\n",
    "# the last argument in the StructField type corresponds to whether the field is nullable\n",
    "schema = types.StructType([\n",
    "    types.StructField('id', types.IntegerType(), True),\n",
    "    types.StructField('name', types.StringType(), True),\n",
    "    types.StructField('date', types.TimestampType(), True)\n",
    "])\n",
    "\n",
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\")\n",
    "    .schema(schema)\n",
    "    .csv('some_csv_file.csv', \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eed6371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"data/fhvhv_tripdata_2023-01.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "509ab613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2:=======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+----------+---------+-------------------+-----+----+---------+--------------------+-----------+----+----------+-------------------+-----------------+------------------+----------------+--------------+\n",
      "|hvfhs_license_num|dispatching_base_num|originating_base_num|   request_datetime|  on_scene_datetime|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|trip_miles|trip_time|base_passenger_fare|tolls| bcf|sales_tax|congestion_surcharge|airport_fee|tips|driver_pay|shared_request_flag|shared_match_flag|access_a_ride_flag|wav_request_flag|wav_match_flag|\n",
      "+-----------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+----------+---------+-------------------+-----+----+---------+--------------------+-----------+----+----------+-------------------+-----------------+------------------+----------------+--------------+\n",
      "|           HV0003|              B03404|              B03404|2023-01-01 01:18:06|2023-01-01 01:19:24|2023-01-01 01:19:38|2023-01-01 01:48:07|          48|          68|      0.94|     1709|              25.95|  0.0|0.78|      2.3|                2.75|        0.0|5.22|     27.83|                  N|                N|                  |               N|             N|\n",
      "|           HV0003|              B03404|              B03404|2023-01-01 01:48:42|2023-01-01 01:56:20|2023-01-01 01:58:39|2023-01-01 02:33:08|         246|         163|      2.78|     2069|              60.14|  0.0| 1.8|     5.34|                2.75|        0.0| 0.0|     50.15|                  N|                N|                  |               N|             N|\n",
      "|           HV0003|              B03404|              B03404|2023-01-01 01:15:35|2023-01-01 01:20:14|2023-01-01 01:20:27|2023-01-01 01:37:54|           9|         129|      8.81|     1047|              24.37|  0.0|0.73|     2.16|                 0.0|        0.0| 0.0|     20.22|                  N|                N|                  |               N|             N|\n",
      "|           HV0003|              B03404|              B03404|2023-01-01 01:35:24|2023-01-01 01:39:30|2023-01-01 01:41:05|2023-01-01 01:48:16|         129|         129|      0.67|      431|               13.8|  0.0|0.41|     1.22|                 0.0|        0.0| 0.0|       7.9|                  N|                N|                  |               N|             N|\n",
      "|           HV0003|              B03404|              B03404|2023-01-01 01:43:15|2023-01-01 01:51:10|2023-01-01 01:52:47|2023-01-01 02:04:51|         129|          92|      4.38|      724|              20.49|  0.0|0.61|     1.82|                 0.0|        0.0| 0.0|     16.48|                  N|                N|                  |               N|             N|\n",
      "+-----------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+----------+---------+-------------------+-----+----+---------+--------------------+-----------+----+----------+-------------------+-----------------+------------------+----------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "168272d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(hvfhs_license_num='HV0003', dispatching_base_num='B03404', originating_base_num='B03404', request_datetime=datetime.datetime(2023, 1, 1, 1, 18, 6), on_scene_datetime=datetime.datetime(2023, 1, 1, 1, 19, 24), pickup_datetime=datetime.datetime(2023, 1, 1, 1, 19, 38), dropoff_datetime=datetime.datetime(2023, 1, 1, 1, 48, 7), PULocationID=48, DOLocationID=68, trip_miles=0.94, trip_time=1709, base_passenger_fare=25.95, tolls=0.0, bcf=0.78, sales_tax=2.3, congestion_surcharge=2.75, airport_fee=0.0, tips=5.22, driver_pay=27.83, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will usually just be a bunch of strings\n",
    "# when you're using a csv, spark doesn't infer\n",
    "# the schema the way pandas does. With parquet\n",
    "# however, the schema *is* read\n",
    "# you can also set \"inferSchema\" option to \"true\"\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8eefffd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[hvfhs_license_num: string, dispatching_base_num: string, originating_base_num: string, request_datetime: timestamp, on_scene_datetime: timestamp, pickup_datetime: timestamp, dropoff_datetime: timestamp, PULocationID: bigint, DOLocationID: bigint, trip_miles: double, trip_time: bigint, base_passenger_fare: double, tolls: double, bcf: double, sales_tax: double, congestion_surcharge: double, airport_fee: double, tips: double, driver_pay: double, shared_request_flag: string, shared_match_flag: string, access_a_ride_flag: string, wav_request_flag: string, wav_match_flag: string]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.repartition(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36fff6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet(\"data/fhv/2023/06\") # mode=' overwrite'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51e106b",
   "metadata": {},
   "source": [
    "# Working With DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0e0d48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"data/fhv/2023/06\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ee4a762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- originating_base_num: string (nullable = true)\n",
      " |-- request_datetime: timestamp (nullable = true)\n",
      " |-- on_scene_datetime: timestamp (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- trip_miles: double (nullable = true)\n",
      " |-- trip_time: long (nullable = true)\n",
      " |-- base_passenger_fare: double (nullable = true)\n",
      " |-- tolls: double (nullable = true)\n",
      " |-- bcf: double (nullable = true)\n",
      " |-- sales_tax: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      " |-- tips: double (nullable = true)\n",
      " |-- driver_pay: double (nullable = true)\n",
      " |-- shared_request_flag: string (nullable = true)\n",
      " |-- shared_match_flag: string (nullable = true)\n",
      " |-- access_a_ride_flag: string (nullable = true)\n",
      " |-- wav_request_flag: string (nullable = true)\n",
      " |-- wav_match_flag: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495e0da3",
   "metadata": {},
   "source": [
    "## Using SQL Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1af5e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------------+------------+----------+\n",
      "|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|   pu_date|\n",
      "+-------------------+-------------------+------------+------------+----------+\n",
      "|2023-01-01 01:19:38|2023-01-01 01:48:07|          48|          68|2023-01-01|\n",
      "|2023-01-01 01:58:39|2023-01-01 02:33:08|         246|         163|2023-01-01|\n",
      "|2023-01-01 01:20:27|2023-01-01 01:37:54|           9|         129|2023-01-01|\n",
      "|2023-01-01 01:41:05|2023-01-01 01:48:16|         129|         129|2023-01-01|\n",
      "|2023-01-01 01:52:47|2023-01-01 02:04:51|         129|          92|2023-01-01|\n",
      "|2023-01-01 01:10:29|2023-01-01 01:18:22|          90|         231|2023-01-01|\n",
      "|2023-01-01 01:22:10|2023-01-01 01:33:14|         125|         246|2023-01-01|\n",
      "|2023-01-01 01:39:09|2023-01-01 02:03:50|          68|         231|2023-01-01|\n",
      "|2023-01-01 01:14:35|2023-01-01 01:49:13|          79|          50|2023-01-01|\n",
      "|2023-01-01 01:52:15|2023-01-01 02:31:11|         143|         223|2023-01-01|\n",
      "|2023-01-01 01:24:48|2023-01-01 01:37:39|          49|         181|2023-01-01|\n",
      "|2023-01-01 01:46:20|2023-01-01 01:52:51|         181|          25|2023-01-01|\n",
      "|2023-01-01 01:53:40|2023-01-01 02:31:23|          25|         143|2023-01-01|\n",
      "|2023-01-01 01:28:05|2023-01-01 01:37:45|         223|           7|2023-01-01|\n",
      "|2023-01-01 01:40:51|2023-01-01 01:54:09|           7|         223|2023-01-01|\n",
      "|2023-01-01 01:59:56|2023-01-01 02:18:47|         223|         145|2023-01-01|\n",
      "|2023-01-01 01:18:26|2023-01-01 01:30:48|         225|          61|2023-01-01|\n",
      "|2023-01-01 01:33:32|2023-01-01 01:48:48|          61|          65|2023-01-01|\n",
      "|2023-01-01 01:59:04|2023-01-01 02:13:50|          33|          80|2023-01-01|\n",
      "|2023-01-01 01:48:17|2023-01-01 02:42:33|          19|          21|2023-01-01|\n",
      "+-------------------+-------------------+------------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('pickup_datetime', 'dropoff_datetime', 'PULocationID', 'DOLocationID') \\\n",
    "    .filter(F.col('hvfhs_license_num') == 'HV0003') \\\n",
    "    .withColumn('pu_date', F.to_date(F.col('pickup_datetime'))) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d760587",
   "metadata": {},
   "source": [
    "### Using UDF\n",
    "UDF == user defined functions (not always the best to use unless you're pretty sure that they are well written and performant AND necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86b92050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crazy_requirement(base_num):\n",
    "    \"\"\"\n",
    "    {num:03x} - this zero pads the integer below to three digits\n",
    "                while the x indicates that\n",
    "    \"\"\"\n",
    "    num = int(base_num[1:])\n",
    "    \n",
    "    if num % 7 == 0:\n",
    "        return f's/{num:03x}'\n",
    "    elif num % 3 == 0:\n",
    "        return f'a/{num:03x}'\n",
    "    else:\n",
    "        return f'e/{num:03x}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b631638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s/b44'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crazy_requirement('B02884')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84ee9304",
   "metadata": {},
   "outputs": [],
   "source": [
    "crazy_udf = F.udf(crazy_requirement, returnType=types.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62b6f294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 12:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------------+------------+--------------------+----------+---------+\n",
      "|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|dispatching_base_num|   pu_date|crazy_col|\n",
      "+-------------------+-------------------+------------+------------+--------------------+----------+---------+\n",
      "|2023-01-01 01:19:38|2023-01-01 01:48:07|          48|          68|              B03404|2023-01-01|    e/d4c|\n",
      "|2023-01-01 01:58:39|2023-01-01 02:33:08|         246|         163|              B03404|2023-01-01|    e/d4c|\n",
      "|2023-01-01 01:20:27|2023-01-01 01:37:54|           9|         129|              B03404|2023-01-01|    e/d4c|\n",
      "|2023-01-01 01:41:05|2023-01-01 01:48:16|         129|         129|              B03404|2023-01-01|    e/d4c|\n",
      "|2023-01-01 01:52:47|2023-01-01 02:04:51|         129|          92|              B03404|2023-01-01|    e/d4c|\n",
      "|2023-01-01 01:10:29|2023-01-01 01:18:22|          90|         231|              B03404|2023-01-01|    e/d4c|\n",
      "|2023-01-01 01:22:10|2023-01-01 01:33:14|         125|         246|              B03404|2023-01-01|    e/d4c|\n",
      "|2023-01-01 01:39:09|2023-01-01 02:03:50|          68|         231|              B03404|2023-01-01|    e/d4c|\n",
      "|2023-01-01 01:14:35|2023-01-01 01:49:13|          79|          50|              B03404|2023-01-01|    e/d4c|\n",
      "|2023-01-01 01:52:15|2023-01-01 02:31:11|         143|         223|              B03404|2023-01-01|    e/d4c|\n",
      "|2023-01-01 01:24:48|2023-01-01 01:37:39|          49|         181|              B03404|2023-01-01|    e/d4c|\n",
      "|2023-01-01 01:46:20|2023-01-01 01:52:51|         181|          25|              B03404|2023-01-01|    e/d4c|\n",
      "|2023-01-01 01:53:40|2023-01-01 02:31:23|          25|         143|              B03404|2023-01-01|    e/d4c|\n",
      "|2023-01-01 01:28:05|2023-01-01 01:37:45|         223|           7|              B03404|2023-01-01|    e/d4c|\n",
      "|2023-01-01 01:40:51|2023-01-01 01:54:09|           7|         223|              B03404|2023-01-01|    e/d4c|\n",
      "|2023-01-01 01:59:56|2023-01-01 02:18:47|         223|         145|              B03404|2023-01-01|    e/d4c|\n",
      "|2023-01-01 01:18:26|2023-01-01 01:30:48|         225|          61|              B03404|2023-01-01|    e/d4c|\n",
      "|2023-01-01 01:33:32|2023-01-01 01:48:48|          61|          65|              B03404|2023-01-01|    e/d4c|\n",
      "|2023-01-01 01:59:04|2023-01-01 02:13:50|          33|          80|              B03404|2023-01-01|    e/d4c|\n",
      "|2023-01-01 01:48:17|2023-01-01 02:42:33|          19|          21|              B03404|2023-01-01|    e/d4c|\n",
      "+-------------------+-------------------+------------+------------+--------------------+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select('pickup_datetime', 'dropoff_datetime', 'PULocationID', 'DOLocationID', 'dispatching_base_num') \\\n",
    "    .filter(F.col('hvfhs_license_num') == 'HV0003') \\\n",
    "    .withColumn('pu_date', F.to_date(F.col('pickup_datetime'))) \\\n",
    "    .withColumn('crazy_col', crazy_udf(F.col('dispatching_base_num'))) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c353a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
